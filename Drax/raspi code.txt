import pickle
import numpy as np
import cv2
import face_recognition
import pyrebase
from datetime import datetime
from picamera.array import PiRGBArray
from picamera import PiCamera
import yagmail

# Firebase configuration
config = {
    "apiKey": "AIzaSyAG_tCDO1bbVTQtRzrKGTbwJLFNbbQzECw",
    "authDomain": "faceattendance-e1faf.firebaseapp.com",
    "databaseURL": "https://faceattendance-e1faf-default-rtdb.firebaseio.com/",
    "storageBucket": "faceattendance-e1faf.appspot.com",
    "serviceAccount": "/home/pi/Desktop/Drax/serviceaccountkey.json"
}

# Email credentials
email_sender = 'draxlmaierit@gmail.com'
email_password = 'sbacgnrfkiodzgjy'

# Initialize Firebase
firebase = pyrebase.initialize_app(config)
storage = firebase.storage()
db = firebase.database()

# Function to send an email with an image attachment
def send_email(image_path):
    subject = 'Alert: Unknown Person Detected'
    contents = 'The code could not recognize the face in the image.'
    attachments = [image_path]

    yag = yagmail.SMTP(email_sender, email_password)
    yag.send(to=email_sender, subject=subject, contents=contents, attachments=attachments)
    yag.close()

# Download file from Firebase Storage
def download_file(filename, destination):
    storage.child(filename).download(destination)

# Download the known face encodings file
download_file("EncodeFile.p", "/home/pi/Desktop/Drax/EncodeFile.p")
print("Encode File Downloaded")

# Load known face encodings
with open('/home/pi/Desktop/Drax/EncodeFile.p', 'rb') as file:
    encodeListKnownWithIds = pickle.load(file)

encodeListKnown, workerId = encodeListKnownWithIds
print(workerId)
print("Encode File Loaded")

# Initialize the PiCamera
camera = PiCamera()
camera.resolution = (320, 240)
camera.framerate = 30
raw_capture = PiRGBArray(camera, size=(320, 240))

# Face recognition variables
known_faces = {}
known_face_encodings = []

for frame in camera.capture_continuous(raw_capture, format="bgr", use_video_port=True):
    image = frame.array

    # Resize the image for faster processing
    imgS = cv2.resize(image, (0, 0), None, 0.25, 0.25)
    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)
    faceCurFrame = face_recognition.face_locations(imgS)
    encodeCurFrame = face_recognition.face_encodings(imgS, faceCurFrame)

    if faceCurFrame:
        for encodeFace, faceLoc in zip(encodeCurFrame, faceCurFrame):
            matches = face_recognition.compare_faces(encodeListKnown, encodeFace)
            faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)
            matchIndex = np.argmin(faceDis)

            if matches[matchIndex]:
                y1, x2, y2, x1 = faceLoc
                y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4
                bbox = (x1, y1, x2 - x1, y2 - y1)
                cv2.rectangle(image, (bbox[0], bbox[1]), (bbox[0] + bbox[2], bbox[1] + bbox[3]), (128, 128, 128), 2)
                id = workerId[matchIndex]

                # Check if the face ID is already in the known_faces dictionary
                if id in known_faces:
                    known_faces[id] += 1
                    print(workerInfo)
                else:
                    known_faces[id] = 1

                if known_faces[id] >= 5:
                    workerInfo = db.child("Workers").child(id).get().val()
                    print(workerInfo)

                    if workerInfo is not None:
                        datetimeObject = datetime.strptime(workerInfo['last_attendance_time'], "%Y-%m-%d %H:%M:%S")
                        secondsElapsed = (datetime.now() - datetimeObject).total_seconds()

                        if secondsElapsed > 30:
                            db.child("Workers").child(id).update({
                                'total_attendance': workerInfo['total_attendance'] + 1,
                                'last_attendance_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                            })

                        (w, h), _ = cv2.getTextSize(workerInfo['name'], cv2.FONT_HERSHEY_COMPLEX, 1, 1)
                        offset = (bbox[2] - w) // 2
                        cv2.putText(image, str(workerInfo['name']), (bbox[0] + offset, bbox[1] - 20),
                                    cv2.FONT_HERSHEY_COMPLEX, 0.6, (255, 0, 0), 1)
                        cv2.putText(image, str(id), (bbox[0] + offset, bbox[1] + bbox[3] + 20),
                                    cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 1)

                    known_faces[id] = 0
            else:
                unknown_encoding = encodeFace
                matches = face_recognition.compare_faces(known_face_encodings, unknown_encoding)
                if not any(matches):
                    image_path = '/home/pi/Desktop/Drax/Unknown/unknown_person.jpg'
                    try:
                        cv2.imwrite(image_path, frame.array)  # Save the frame as an image
                        send_email(image_path)
                    except cv2.error as e:
                        print(f"Error saving image: {e}")
                known_face_encodings.append(unknown_encoding)

                known_faces[id] = 0

    else:
        known_faces = {}

    cv2.imshow("Face Attendance", image)
    key = cv2.waitKey(1) & 0xFF

    # Clear the stream for the next frame
    raw_capture.truncate(0)

    # If the 'q' key was pressed, break from the loop
    if key == ord("q"):
        break

cv2.destroyAllWindows()
